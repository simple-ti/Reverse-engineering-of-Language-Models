<h1 align="center"><b>Towards Reverse Engineering of Language Model: A Survey</b></h1>

## NEWS

- **[Sep/2025]** We release this paper on arxiv. Check our paper on 


### Introduction


With the continuous development of language
models and the widespread availability of var-
ious types of accessible interfaces, large lan-
guage models (LLMs) have been applied to
an increasing number of fields. However, due
to the vast amounts of data and computational
resources required for model development, pro-
tecting the model’s parameters and training
data has become an urgent and crucial concern.
Due to the revolutionary training and applica-
tion paradigms of LLMs, many new attacks on
language models have emerged in recent years.
In this paper, we define these attacks as “reverse
engineering” (RE) techniques on LMs and aim
to provide an in-depth analysis of reverse en-
gineering of language models. We illustrate
various methods of reverse engineering applied
to different aspects of a model, while also pro-
viding an introduction to existing protective
strategies. On the one hand, it demonstrates
the vulnerabilities of even black box models to
different types of attacks; on the other hand, it
offers a more holistic perspective for the devel-
opment of new protective strategies for models.







### **Citation**

If you find this repo helpful, please kindly cite our [paper]. Thank you :)


